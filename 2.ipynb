{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyG4bCznATmd",
        "colab_type": "code",
        "outputId": "b6d756dc-2bfc-404f-cd1c-c1668f857735",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5HdPiYTBx8a",
        "colab_type": "code",
        "outputId": "06388b95-019c-4548-ad9a-aff4955dc48a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZNTDBls--Oe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.enable_eager_execution()\n",
        "# You'll generate plots of attention in order to see which parts of an image\n",
        "# our model focuses on during captioning\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Scikit-learn includes many helpful utilities\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkcwBrrkArVA",
        "colab_type": "code",
        "outputId": "d6053a54-1c21-4f4d-82b6-2b61f1194f8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "# import tensorflow as tf\n",
        "import xml.etree.ElementTree\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "from PIL import Image\n",
        "from numpy import array\n",
        "import string\n",
        "import os\n",
        "from PIL import Image\n",
        "import glob\n",
        "from pickle import dump, load\n",
        "from time import time\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Embedding, TimeDistributed, Dense, RepeatVector,\\\n",
        "                         Activation, Flatten, Reshape, concatenate, Dropout, BatchNormalization\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras.layers.wrappers import Bidirectional\n",
        "from keras.layers.merge import add\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Model\n",
        "from keras import Input, layers\n",
        "from keras import optimizers\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNXKHthJBLZy",
        "colab_type": "code",
        "outputId": "dbde662e-1ad8-4e3a-8a03-e30c6e0c3784",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIzoNS1xBPUh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## https://github.com/wisdal/diagnose-and-explain/blob/master/prepare_dataset.py\n",
        "\n",
        "def extract_data():\n",
        "    all_findings = []\n",
        "    all_impressions = []\n",
        "    all_img_names = []\n",
        "    rids = []\n",
        "    \n",
        "    total_count = 0 # Count of reports available in the dataset\n",
        "    no_image_count = 0 # Count of reports having no associated chest image\n",
        "    no_impression_count = 0 # Count of reports having an empty \"Impression\" section\n",
        "    no_findings_count = 0 # Count of reports having an empty \"Findings\" section\n",
        "\n",
        "    # Storing impressions, findings and the image names in vectors\n",
        "    for file in tqdm(os.listdir(annotation_folder)):\n",
        "        total_count += 1\n",
        "        file = os.path.abspath(annotation_folder) + '/' + file\n",
        "        e = xml.etree.ElementTree.parse(file).getroot()\n",
        "\n",
        "        rid = e.find('pmcId').get('id') # Report Id\n",
        "        # We choose to ignore reports having no associated image\n",
        "        image_id = e.find('parentImage')\n",
        "        if image_id is None:\n",
        "            no_image_count += 1\n",
        "            continue\n",
        "\n",
        "        image_id = image_id.get('id')\n",
        "#         image_name = os.path.abspath('.') + '/' + image_id + '.png'\n",
        "        image_name = image_folder + '/' + image_id + '.png'\n",
        "        findings = ''\n",
        "        impression = ''\n",
        "\n",
        "        # Parsing \"Impression\" and \"Findings\"\n",
        "        for element in e.findall('MedlineCitation/Article/Abstract/AbstractText'):\n",
        "            if element.get('Label') == 'FINDINGS':\n",
        "                findings = element.text\n",
        "            if element.get('Label') == 'IMPRESSION':\n",
        "                impression = element.text\n",
        "\n",
        "        # Sanity check: Skip this report if it has an empty \"Impression\" section\n",
        "        if findings is None:\n",
        "            no_findings_count += 1\n",
        "            #findings = 'No finding'\n",
        "            continue\n",
        "        if impression is None:\n",
        "            no_impression_count += 1\n",
        "            continue\n",
        "        \n",
        "        # Transforming findings and impressions into lists of sentences\n",
        "        # https://stackoverflow.com/questions/21840389/python-regular-expression-remove-period-from-number-at-end-of-sentence\n",
        "        findings = findings.replace(\"XXXX\", \"\") #\"XXXX\" represents information anonymized\n",
        "        findings=re.sub('((\\d+)[\\.])(?!([\\d]+))','\\g<2>',findings)\n",
        "        findings = re.sub(\" \\d+\", \" \", findings)\n",
        "#         sentences = findings.split('.')\n",
        "        sentences = findings\n",
        "#         del sentences[-1]\n",
        "#         sentences = ['<start> ' + sentence + ' <end>' for sentence in sentences]\n",
        "        sentences = ['<start> ' + sentences + ' <end>']\n",
        "        findings = sentences\n",
        "\n",
        "        impression = impression.replace(\"XXXX\", \"\") #\"XXXX\" represents information anonymized\n",
        "        impression=re.sub('((\\d+)[\\.])(?!([\\d]+))','\\g<2>',impression)\n",
        "        impression = re.sub(\" \\d+\", \" \", impression)\n",
        "#https://www.tutorialspoint.com/How-to-remove-specific-characters-from-a-string-in-Python\n",
        "        impression=impression.replace(\"1\", \"\")\n",
        "#         sentences = impression.split('.')\n",
        "#         del sentences[-1]\n",
        "        sentences = impression\n",
        "#         sentences = ['<start> ' + sentence + ' <end>' for sentence in sentences]\n",
        "        sentences = ['<start> ' + sentences + ' <end>' ]\n",
        "        impression = sentences\n",
        "\n",
        "        #appending to vectors\n",
        "        all_img_names.append(image_name)\n",
        "        all_findings.append(findings)\n",
        "        all_impressions.append(impression)\n",
        "        rids.append(rid)\n",
        "\n",
        "    print(\"Number of reports available:\", total_count)\n",
        "    print(\"Number of reports selected:\", len(all_img_names))\n",
        "    print(\"Number of reports not having images (skipped):\", no_image_count)\n",
        "    print(\"Number of reports with Impression section empty (skipped):\", no_impression_count)\n",
        "    print(\"Number of reports with Findings section empty:\", no_findings_count)\n",
        "    print(\"Total skipped:\", no_image_count + no_impression_count + no_findings_count)\n",
        "\n",
        "    return all_findings, all_impressions, all_img_names, rids"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAW0byL3QpfO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_folder = '/content/drive/My Drive/Colab Notebooks/Medical data case study'\n",
        "annotation_folder = '/content/drive/My Drive/Colab Notebooks/Medical data case study/ecgen-radiology'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDC0v96kKOnH",
        "colab_type": "code",
        "outputId": "b717cf32-2b4d-43a1-dbfd-7c5736c91aa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "all_findings, all_impressions, all_img_names, report_id=extract_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3955/3955 [00:09<00:00, 414.64it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Number of reports available: 3955\n",
            "Number of reports selected: 3331\n",
            "Number of reports not having images (skipped): 104\n",
            "Number of reports with Impression section empty (skipped): 6\n",
            "Number of reports with Findings section empty: 514\n",
            "Total skipped: 624\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PllY63kcKOqD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Converting Lists to Dataframe\n",
        "## https://stackoverflow.com/questions/30522724/take-multiple-lists-into-dataframe\n",
        "df = pd.DataFrame(\n",
        "    { 'report_id':report_id,\n",
        "        'findings': all_findings,\n",
        "     'impressions': all_impressions,\n",
        "     'image_names': all_img_names\n",
        "    })"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cu381Oi5KOsi",
        "colab_type": "code",
        "outputId": "fa9775de-c37a-451d-f946-2978946ac696",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "df.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>report_id</th>\n",
              "      <th>findings</th>\n",
              "      <th>impressions</th>\n",
              "      <th>image_names</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>584</td>\n",
              "      <td>[&lt;start&gt; There are no focal areas of consolida...</td>\n",
              "      <td>[&lt;start&gt; No acute cardiopulmonary abnormality....</td>\n",
              "      <td>/content/drive/My Drive/Colab Notebooks/Medica...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>580</td>\n",
              "      <td>[&lt;start&gt; The heart is normal in size. The medi...</td>\n",
              "      <td>[&lt;start&gt; No acute disease. &lt;end&gt;]</td>\n",
              "      <td>/content/drive/My Drive/Colab Notebooks/Medica...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>585</td>\n",
              "      <td>[&lt;start&gt; There are prominent epicardial fat pa...</td>\n",
              "      <td>[&lt;start&gt; No acute cardiopulmonary abnormality....</td>\n",
              "      <td>/content/drive/My Drive/Colab Notebooks/Medica...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>581</td>\n",
              "      <td>[&lt;start&gt; Frontal and lateral views of the ches...</td>\n",
              "      <td>[&lt;start&gt; No acute or active cardiac, pulmonary...</td>\n",
              "      <td>/content/drive/My Drive/Colab Notebooks/Medica...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>586</td>\n",
              "      <td>[&lt;start&gt; The heart size is moderately enlarged...</td>\n",
              "      <td>[&lt;start&gt; Probable left midlung and left basila...</td>\n",
              "      <td>/content/drive/My Drive/Colab Notebooks/Medica...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>582</td>\n",
              "      <td>[&lt;start&gt; Cardiomediastinal silhouette and pulm...</td>\n",
              "      <td>[&lt;start&gt; No acute cardiopulmonary findings. &lt;e...</td>\n",
              "      <td>/content/drive/My Drive/Colab Notebooks/Medica...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>589</td>\n",
              "      <td>[&lt;start&gt; Heart size normal. Lungs are clear.  ...</td>\n",
              "      <td>[&lt;start&gt; Normal chest &lt;end&gt;]</td>\n",
              "      <td>/content/drive/My Drive/Colab Notebooks/Medica...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>587</td>\n",
              "      <td>[&lt;start&gt; The cardiomediastinal silhouette is w...</td>\n",
              "      <td>[&lt;start&gt;  No interval change in the appearance...</td>\n",
              "      <td>/content/drive/My Drive/Colab Notebooks/Medica...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>59</td>\n",
              "      <td>[&lt;start&gt; The cardiac silhouette, mediastinum, ...</td>\n",
              "      <td>[&lt;start&gt; No acute abnormalities are seen. . &lt;e...</td>\n",
              "      <td>/content/drive/My Drive/Colab Notebooks/Medica...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>590</td>\n",
              "      <td>[&lt;start&gt; The cardiomediastinal silhouette is n...</td>\n",
              "      <td>[&lt;start&gt; Right middle lobe airspace disease ma...</td>\n",
              "      <td>/content/drive/My Drive/Colab Notebooks/Medica...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  report_id  ...                                        image_names\n",
              "0       584  ...  /content/drive/My Drive/Colab Notebooks/Medica...\n",
              "1       580  ...  /content/drive/My Drive/Colab Notebooks/Medica...\n",
              "2       585  ...  /content/drive/My Drive/Colab Notebooks/Medica...\n",
              "3       581  ...  /content/drive/My Drive/Colab Notebooks/Medica...\n",
              "4       586  ...  /content/drive/My Drive/Colab Notebooks/Medica...\n",
              "5       582  ...  /content/drive/My Drive/Colab Notebooks/Medica...\n",
              "6       589  ...  /content/drive/My Drive/Colab Notebooks/Medica...\n",
              "7       587  ...  /content/drive/My Drive/Colab Notebooks/Medica...\n",
              "8        59  ...  /content/drive/My Drive/Colab Notebooks/Medica...\n",
              "9       590  ...  /content/drive/My Drive/Colab Notebooks/Medica...\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aY8E1cAIzTRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_captions, img_name_vector = shuffle(all_impressions,\n",
        "                                          all_img_names,\n",
        "                                          random_state=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAkhkblyzTVL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_image(image_path):\n",
        "    img = tf.io.read_file(image_path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, (512, 624))\n",
        "    img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
        "    return img, image_path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2DRGhRN_CHd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_model = tf.keras.applications.InceptionV3(include_top=False,\n",
        "                                                weights='imagenet')\n",
        "new_input = image_model.input\n",
        "hidden_layer = image_model.layers[-2].output\n",
        "\n",
        "image_features_extract_model = tf.keras.Model(new_input, hidden_layer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XI482dD3_-jA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tf.enable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWPMpSOv_T-g",
        "colab_type": "code",
        "outputId": "04d80270-cb64-4461-f390-1165ef2fcb6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# Get unique images\n",
        "encode_train = sorted(set(img_name_vector))\n",
        "\n",
        "# Feel free to change batch_size according to your system configuration\n",
        "image_dataset = tf.data.Dataset.from_tensor_slices(encode_train)\n",
        "image_dataset = image_dataset.map(\n",
        "  load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(16)\n",
        "\n",
        "for img, path in image_dataset:\n",
        "  batch_features = image_features_extract_model(img)\n",
        "  batch_features = tf.reshape(batch_features,\n",
        "                              (batch_features.shape[0], -1, batch_features.shape[3]))\n",
        "\n",
        "  for bf, p in zip(batch_features, path):\n",
        "    path_of_feature = p.numpy().decode(\"utf-8\")\n",
        "    np.save(path_of_feature, bf.numpy())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function load_image at 0x7f634c9648c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <function load_image at 0x7f634c9648c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAW_Irpz_UBk",
        "colab_type": "code",
        "outputId": "f14633cd-0cf9-42a0-db94-6a81e467f30a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "1-2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BR477R7_CKb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzmmGu3c_CNI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWbJCH4YKOvi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(df['findings'][3])\n",
        "print(\"-\"*50)\n",
        "print(df['impressions'][3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phWS4l4dKOyI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Image(filename=df['image_names'][i], width=300, height=300) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vMlQtB2KO0v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### https://pythonadventures.wordpress.com/2011/04/04/get-the-size-dimension-of-an-image/\n",
        "# for i in range(10):\n",
        "#     image_file = df['image_names'][i]\n",
        "#     im = Image.open(image_file)\n",
        "#     print(im.size)   # return value is a tuple, ex.: (1200, 800)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLqE6FnAMxm1",
        "colab_type": "text"
      },
      "source": [
        "#### We would take size of image as (512,624)\n",
        "for details uncomment the above snippet and run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gg8KrZgTMzhY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_image(image_path):\n",
        "    # Convert all the images to size 299x299 as expected by the inception v3 model\n",
        "    img = image.load_img(image_path, target_size=(512, 624))\n",
        "    # Convert PIL image to numpy array of 3-dimensions\n",
        "    x = image.img_to_array(img)\n",
        "    # Add one more dimension\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    # preprocess the images using preprocess_input() from inception module\n",
        "    x = preprocess_input(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiZoutBoMzgr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the inception v3 model\n",
        "model = InceptionV3(weights='imagenet')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHf6Oq24M5_x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a new model, by removing the last layer (output layer) from the inception v3\n",
        "model_new = Model(model.input, model.layers[-2].output)\n",
        "# # model.add(Dense(4096))\n",
        "# b=Dense(4096)(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WQKy61fM8xF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to encode a given image into a vector of size (2048, )\n",
        "def encode(image):\n",
        "    image = preprocess_image(image) # preprocess the image\n",
        "    fea_vec = model_new.predict(image) # Get the encoding vector for the image\n",
        "    fea_vec = np.reshape(fea_vec, fea_vec.shape[1]) # reshape from (1, 2048) to (2048, )\n",
        "    return fea_vec\n",
        "# Call the funtion to encode all the train images\n",
        "# This will take a while on CPU - Execute this only once\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnh1WQejM_KW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start = time()\n",
        "encoding_train = {}\n",
        "for img in tqdm(df['image_names']):\n",
        "    encoding_train[img] = encode(img)\n",
        "print(\"Time taken in seconds =\", time()-start)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yn3Ahk_NCcE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoding_train[img].shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8zrLqDkNFKt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the bottleneck train features to disk\n",
        "with open(\"./encoded_train_images.pkl\", \"wb\") as encoded_pickle:\n",
        "    pickle.dump(encoding_train, encoded_pickle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aI7d8jgqNHWV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_features = load(open(\"./encoded_train_images.pkl\", \"rb\"))\n",
        "print('Photos: train=%d' % len(train_features))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcDp62xPNK2O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}